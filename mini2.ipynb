{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tharunkumar1818/mini2?scriptVersionId=205166863\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# install datasets\n!pip install datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-04T11:23:38.961407Z","iopub.execute_input":"2024-11-04T11:23:38.961708Z","iopub.status.idle":"2024-11-04T11:23:51.431216Z","shell.execute_reply.started":"2024-11-04T11:23:38.96167Z","shell.execute_reply":"2024-11-04T11:23:51.430298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\nbig_multilabel_dataset = load_dataset(path=\"mwritescode/slither-audited-smart-contracts\", name=\"big-multilabel\")","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:23:51.433047Z","iopub.execute_input":"2024-11-04T11:23:51.433376Z","iopub.status.idle":"2024-11-04T11:26:04.679503Z","shell.execute_reply.started":"2024-11-04T11:23:51.433343Z","shell.execute_reply":"2024-11-04T11:26:04.678561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_data(dataset):\n  cleaned_data = []\n  for data in dataset:\n    # clean the bytecode and the 4 output that represents if the contract is safe\n    if (len(data['bytecode']) > 4):\n      if (4 in data['slither']):\n       data['slither'].remove(4)\n      new_slither_output = []\n      for output in data['slither']:\n         if (output > 4):\n           new_slither_output.append(output - 1)\n         else:\n           new_slither_output.append(output)\n      data['slither']=new_slither_output\n      cleaned_data.append(data)\n  return cleaned_data\n\ncleaned_training_data = clean_data(big_multilabel_dataset[\"train\"])\ncleaned_validation_data = clean_data(big_multilabel_dataset[\"validation\"])\ncleaned_test_data = clean_data(big_multilabel_dataset[\"test\"])\n\nlen(cleaned_training_data), len(cleaned_validation_data), len(cleaned_test_data)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:26:04.680797Z","iopub.execute_input":"2024-11-04T11:26:04.681211Z","iopub.status.idle":"2024-11-04T11:26:16.84092Z","shell.execute_reply.started":"2024-11-04T11:26:04.681164Z","shell.execute_reply":"2024-11-04T11:26:16.839989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_text_into_chars(text, length):\n  return \" \".join([text[i:i+length] for i in range(0, len(text), length)])\ntrain_bytecode = [split_text_into_chars(data['bytecode'][2:],1) for data in cleaned_training_data]\ntest_bytecode = [split_text_into_chars(data['bytecode'][2:],1) for data in cleaned_test_data]\nval_bytecode = [split_text_into_chars(data['bytecode'][2:],1) for data in  cleaned_validation_data]","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:26:16.844756Z","iopub.execute_input":"2024-11-04T11:26:16.845076Z","iopub.status.idle":"2024-11-04T11:31:27.288881Z","shell.execute_reply.started":"2024-11-04T11:26:16.845043Z","shell.execute_reply":"2024-11-04T11:31:27.288064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nbytecodes_length = [len(bytecode.split()) for bytecode in train_bytecode]\noutput_seq_len = int(np.percentile(bytecodes_length, 95))\n\n# Find the maximu number of tokens that could represent the bytecode\nimport string\nmax_tokens = (len(string.hexdigits) - 6) ** 2","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:31:27.289953Z","iopub.execute_input":"2024-11-04T11:31:27.29029Z","iopub.status.idle":"2024-11-04T11:31:49.19635Z","shell.execute_reply.started":"2024-11-04T11:31:27.29025Z","shell.execute_reply":"2024-11-04T11:31:49.195361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ntraining_slither = [data['slither'] for data in cleaned_training_data]\nvalidation_slither = [data['slither'] for data in cleaned_validation_data]\ntest_slither = [data['slither'] for data in cleaned_test_data]\n\nnum_classes = len(np.unique(np.concatenate(training_slither)))","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:31:49.197576Z","iopub.execute_input":"2024-11-04T11:31:49.197956Z","iopub.status.idle":"2024-11-04T11:31:49.355063Z","shell.execute_reply.started":"2024-11-04T11:31:49.197908Z","shell.execute_reply":"2024-11-04T11:31:49.354245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert labels to binary vectors\nimport numpy as np\n\ndef labels_to_binary(y, num_labels):\n    \"\"\"\n    Converts the labels into binary format\n    depending on the total number of labels,\n    for example: y = [1,4], num_labels = 5, y_binary = [0,1,0,0,1,0]\n    \"\"\"\n    y_binary = np.zeros((len(y), num_labels), dtype=float)\n    for i, label_indices in enumerate(y):\n        y_binary[i, label_indices] = 1\n    return y_binary\n\ntrain_labels_binary = labels_to_binary(training_slither, num_classes)\nvalid_labels_binary = labels_to_binary(validation_slither, num_classes)\ntest_labels_binary = labels_to_binary(test_slither, num_classes)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:31:49.356143Z","iopub.execute_input":"2024-11-04T11:31:49.35646Z","iopub.status.idle":"2024-11-04T11:31:49.740275Z","shell.execute_reply.started":"2024-11-04T11:31:49.356426Z","shell.execute_reply":"2024-11-04T11:31:49.739297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_labels_to_dict(labels_binary):\n    labels_dict = {}\n    for index in range(num_classes):\n        labels_dict[f'{index}'] = []\n\n    for labels in labels_binary:\n        for index, label in enumerate(labels):\n            labels_dict[f'{index}'].append(label)\n    \n    return labels_dict  # Correctly indented return statement\n\nvalidation_dict = transform_labels_to_dict(valid_labels_binary)\ntrain_dict = transform_labels_to_dict(train_labels_binary)\ntest_dict = transform_labels_to_dict(test_labels_binary)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:31:49.741702Z","iopub.execute_input":"2024-11-04T11:31:49.742389Z","iopub.status.idle":"2024-11-04T11:31:50.085178Z","shell.execute_reply.started":"2024-11-04T11:31:49.742341Z","shell.execute_reply":"2024-11-04T11:31:50.084168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_bytecode, train_dict)).batch(32).prefetch(tf.data.AUTOTUNE)\nvalidation_dataset = tf.data.Dataset.from_tensor_slices((val_bytecode, validation_dict)).batch(32).prefetch(tf.data.AUTOTUNE)\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_bytecode, test_dict)).batch(32).prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:31:50.086514Z","iopub.execute_input":"2024-11-04T11:31:50.087209Z","iopub.status.idle":"2024-11-04T11:32:19.836688Z","shell.execute_reply.started":"2024-11-04T11:31:50.087163Z","shell.execute_reply":"2024-11-04T11:32:19.835776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_tokens=100\noutput_seq_len = 21041\ntext_vectorizer = tf.keras.layers.TextVectorization(\n    split=\"whitespace\",\n    max_tokens=max_tokens,\n    output_sequence_length=output_seq_len\n)\ntext_vectorizer.adapt(tf.data.Dataset.from_tensor_slices(train_bytecode).batch(32).prefetch(tf.data.AUTOTUNE))","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:32:19.839932Z","iopub.execute_input":"2024-11-04T11:32:19.840264Z","iopub.status.idle":"2024-11-04T11:35:46.011196Z","shell.execute_reply.started":"2024-11-04T11:32:19.84023Z","shell.execute_reply":"2024-11-04T11:35:46.010233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bytecode_vocab = text_vectorizer.get_vocabulary()\nprint(f\"Number of different characters in vocab: {len(bytecode_vocab)}\")\nprint(f\"5 most common characters: {bytecode_vocab[:5]}\")\nprint(f\"5 least common characters: {bytecode_vocab[-5:]}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:35:46.01254Z","iopub.execute_input":"2024-11-04T11:35:46.012954Z","iopub.status.idle":"2024-11-04T11:35:46.020945Z","shell.execute_reply.started":"2024-11-04T11:35:46.012905Z","shell.execute_reply":"2024-11-04T11:35:46.020012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_layer = tf.keras.layers.Embedding(\ninput_dim=len(bytecode_vocab),\ninput_length=output_seq_len,\noutput_dim=128,\nmask_zero=False, # Conv layers do not support masking\nname=\"embedding_layer\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:35:46.022264Z","iopub.execute_input":"2024-11-04T11:35:46.02264Z","iopub.status.idle":"2024-11-04T11:35:46.030149Z","shell.execute_reply.started":"2024-11-04T11:35:46.022596Z","shell.execute_reply":"2024-11-04T11:35:46.029251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\n# Create the input layer\ninputs = layers.Input(shape=(1,), dtype=tf.string, name=\"input_layer\")\n\n# Create the bytecode tokens\nx = text_vectorizer(inputs)\n\n# Create the embedding layer\nx = embedding_layer(x)\n\n# Create the first block\nx = layers.Conv1D(filters=4, kernel_size=3, strides=1, padding='valid', name=\"conv_layer_2\")(x)\nx = layers.Conv1D(filters=4, kernel_size=3, strides=1, padding='valid', name=\"conv_layer_3\")(x)\nx = layers.MaxPooling1D()(x)\n\n# Create the second block\nx = layers.Conv1D(filters=8, kernel_size=3, strides=1, padding='valid', name=\"conv_layer_4\")(x)\nx = layers.Conv1D(filters=8, kernel_size=3, strides=1, padding='valid', name=\"conv_layer_5\")(x)\nx = layers.MaxPooling1D()(x)\n\n# Create the third block\nx = layers.Conv1D(filters=16, kernel_size=3, strides=1, padding='valid', name=\"conv_layer_6\")(x)\nx = layers.Conv1D(filters=16, kernel_size=3, strides=1, padding='valid', name=\"conv_layer_7\")(x)\nx = layers.MaxPooling1D()(x)\n\n# Add the global max layer\nx = layers.GlobalMaxPooling1D()(x)\n\n# Add a dense layer\nx = layers.Dense(32, activation=\"relu\")(x)\n\n# Create the output layers\noutputs = []\nfor index in range(num_classes):\n    output = layers.Dense(1, activation=\"sigmoid\", name=f'{index}')(x)\n    outputs.append(output)\n\n# Create the model\nmodel_1 = tf.keras.Model(inputs, outputs, name=\"model_1\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:35:46.031376Z","iopub.execute_input":"2024-11-04T11:35:46.031701Z","iopub.status.idle":"2024-11-04T11:35:46.177923Z","shell.execute_reply.started":"2024-11-04T11:35:46.031661Z","shell.execute_reply":"2024-11-04T11:35:46.177227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses={}\nmetrics={}\nfor index in range(num_classes):\n  losses[f'{index}'] = \"binary_crossentropy\"\n  metrics[f'{index}'] = ['accuracy']\nmodel_1.compile(loss=losses, optimizer=tf.keras.optimizers.Adam(learning_rate=1e-03), metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:35:46.179361Z","iopub.execute_input":"2024-11-04T11:35:46.179727Z","iopub.status.idle":"2024-11-04T11:35:46.194081Z","shell.execute_reply.started":"2024-11-04T11:35:46.179684Z","shell.execute_reply":"2024-11-04T11:35:46.193376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_1 = model_1.fit(train_dataset,\n                        epochs=35,\n                        validation_data=validation_dataset,\n                        callbacks=[\n                                   tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                                        patience=5),\n                                   tf.keras.callbacks.ModelCheckpoint(filepath=f\"model_experiments/model_1.keras\",  # Add .keras extension\n                                                                      monitor='val_loss',\n                                                                      verbose=0,\n                                                                      save_best_only=True)\n                                  ])\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:35:46.196853Z","iopub.execute_input":"2024-11-04T11:35:46.197386Z","iopub.status.idle":"2024-11-04T15:01:15.111079Z","shell.execute_reply.started":"2024-11-04T11:35:46.197353Z","shell.execute_reply":"2024-11-04T15:01:15.110266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Create a subplot for accuracy\nplt.subplot(1, 2, 1)\n\n# Loop through the number of classes to plot each accuracy\nfor index in range(num_classes):\n    plt.plot(history_1.history[f'{index}_accuracy'], label=f'Train Accuracy {index}')\n    plt.plot(history_1.history[f'val_{index}_accuracy'], label=f'Validation Accuracy {index}')\n\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(loc='upper left')\n\n# Create a subplot for loss\nplt.subplot(1, 2, 2)\nplt.plot(history_1.history['loss'], label='Train Loss')\nplt.plot(history_1.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(loc='upper left')\n\n# Adjust layout\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T15:03:05.367052Z","iopub.execute_input":"2024-11-04T15:03:05.367755Z","iopub.status.idle":"2024-11-04T15:03:05.904504Z","shell.execute_reply.started":"2024-11-04T15:03:05.367716Z","shell.execute_reply":"2024-11-04T15:03:05.903539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_preds_probs_to_preds(preds_probs):\n    preds = []  # List to hold the final predictions\n    for pred_prob in preds_probs:\n        # Convert probabilities to binary predictions\n        converted_pred_prob = [1 if value[0] >= 0.5 else 0 for value in pred_prob]\n        preds.append(converted_pred_prob)\n    \n    preds_dict = {}  # Dictionary to hold predictions for each output\n    for index in range(len(preds)):\n        preds_dict[f'{index}'] = preds[index]  # Assign predictions to respective keys\n    \n    return preds_dict\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T15:03:10.050428Z","iopub.execute_input":"2024-11-04T15:03:10.051341Z","iopub.status.idle":"2024-11-04T15:03:10.056902Z","shell.execute_reply.started":"2024-11-04T15:03:10.051298Z","shell.execute_reply":"2024-11-04T15:03:10.055976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef calculate_results(y_true, y_pred):\n    \"\"\"\n    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n\n    Args:\n    y_true: true labels in the form of a 1D array\n    y_pred: predicted labels in the form of a 1D array\n\n    Returns a dictionary of accuracy, precision, recall, f1-score.\n    \"\"\"\n    # Calculate model accuracy\n    model_accuracy = accuracy_score(y_true, y_pred) * 100\n    # Calculate model precision, recall and f1 score using \"weighted average\"\n    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n    model_results = {\n        \"accuracy\": model_accuracy,\n        \"precision\": model_precision,\n        \"recall\": model_recall,\n        \"f1\": model_f1\n    }\n    return model_results\n\ndef combine_results(y_true, y_pred):\n    results = {}\n    for index in range(num_classes):\n        results[f'{index}'] = calculate_results(y_true=test_dict[f'{index}'], y_pred=model_1_preds[f'{index}'])\n    return results\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T15:03:12.501324Z","iopub.execute_input":"2024-11-04T15:03:12.501988Z","iopub.status.idle":"2024-11-04T15:03:12.509008Z","shell.execute_reply.started":"2024-11-04T15:03:12.501949Z","shell.execute_reply":"2024-11-04T15:03:12.508075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 1: Generate predictions on the test dataset\nmodel_1_preds_probs = model_1.predict(test_dataset)\n\n# Step 2: Convert probabilities to binary predictions\nmodel_1_preds = convert_preds_probs_to_preds(model_1_preds_probs)\n\n# Step 3: Combine results to calculate metrics\nresults = combine_results(y_true=test_dict, y_pred=model_1_preds)\n\n# Step 4: Create a DataFrame from the results for visualization\nimport pandas as pd\nresults_df = pd.DataFrame(results)\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T15:03:14.836947Z","iopub.execute_input":"2024-11-04T15:03:14.837355Z","iopub.status.idle":"2024-11-04T15:03:56.991354Z","shell.execute_reply.started":"2024-11-04T15:03:14.837309Z","shell.execute_reply":"2024-11-04T15:03:56.990334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# Make predictions on the test set using the correct model\n# Make sure to predict using the appropriate dataset\n# For a model with multiple outputs, you may need to use the test dataset accordingly\nmodel_1_preds_probs = model_1.predict(test_dataset)  # Use your trained model here\n\n# Convert probabilities to binary class labels\nmodel_1_preds = convert_preds_probs_to_preds(model_1_preds_probs)\n\n# Convert predictions to a format suitable for confusion matrix calculation\n# Assuming test_dict contains the true labels for each class\ny_pred_classes = [np.argmax(pred) for pred in model_1_preds.values()]  # Modify according to your structure\ny_test_classes = [np.argmax(true) for true in test_dict.values()]  # Convert test_dict to class labels\n\n# Generate the confusion matrix\ncm = confusion_matrix(y_test_classes, y_pred_classes)\n\n# Plot confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T15:03:56.993262Z","iopub.execute_input":"2024-11-04T15:03:56.993592Z","iopub.status.idle":"2024-11-04T15:04:39.558103Z","shell.execute_reply.started":"2024-11-04T15:03:56.993557Z","shell.execute_reply":"2024-11-04T15:04:39.557172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model after training\nmodel_1.save(\"/kaggle/working/model_1.h5\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T15:04:43.895428Z","iopub.execute_input":"2024-11-04T15:04:43.896326Z","iopub.status.idle":"2024-11-04T15:04:43.977818Z","shell.execute_reply.started":"2024-11-04T15:04:43.896273Z","shell.execute_reply":"2024-11-04T15:04:43.976869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Input\nimport os\n\n# Create and compile your model\nmodel = Sequential()\nmodel.add(Input(shape=(784,)))  # Use Input layer to specify the input shape\nmodel.add(Dense(32, activation='relu'))  # First hidden layer\nmodel.add(Dense(10, activation='softmax'))  # Output layer for 10 classes\n\n# Compile the model\nmodel.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\n\n# Save the model\nmodel.save('my_model.h5')\n\n# Check if the file exists\nprint(os.listdir('.'))  # Should show 'my_model.h5'\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T15:21:55.876176Z","iopub.execute_input":"2024-11-04T15:21:55.877176Z","iopub.status.idle":"2024-11-04T15:21:55.923729Z","shell.execute_reply.started":"2024-11-04T15:21:55.877133Z","shell.execute_reply":"2024-11-04T15:21:55.922771Z"},"trusted":true},"execution_count":null,"outputs":[]}]}